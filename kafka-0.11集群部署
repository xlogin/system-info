原文   https://segmentfault.com/a/1190000010041375
环境
Zookeeper集群:172.16.218.201、172.16.218.202、172.16.218.203
172.16.218.201 kafka1
172.16.218.202 kafka2
172.16.218.203 kafka3
172.16.200.48 kafka-manager

一、部署zookeeper集群(201、202、203)
1、下载zookeeper安装包
wget http://mirrors.cnnic.cn/apache/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gz
2、添加host
# vi /etc/hosts
172.16.218.201 zookeeper1-201
172.16.218.202 zookeeper2-202
172.16.218.203 zookeeper3-203
3、安装zookeeper，将安装包放在/usr/local/下，解压
# tar zxvf zookeeper-3.4.10.tar.gz
# cd zookeeper-3.4.10
# mv zookeeper-3.4.10 zookeeper
# chown -R root. /usr/local/zookeeper-node1 
# cd /usr/local/zookepper-node1/conf/
# cp zoo_sample.cfg zoo.cfg  
4、安装JDK，zookeeper要用到,将安装包放在/usr/local/下，解压
# tar zxvf jdk-8u74-linux-x64.tar.gz
# mv jdk1.8.0_131 /usr/local/java/
5、修改环境变量为 vim /etc/profile 在最后添加以下内容：
#add java
export JAVA_HOME=/usr/local/java/jdk1.8.0_131
export JAVA_BIN=/usr/local/java/jdk1.8.0_131/bin
export PATH=$PATH:/usr/local/java/jdk1.8.0_131/bin
export CLASSPATH=./:/usr/local/java/jdk1.8.0_131/lib:/usr/local/java/jdk1.8.0_131/jre/lib
#然后执行 source /etc/profile
6、撰写zk的配置文件, # vi /usr/local/zookeeper/conf/zoo.cfg
tickTime=2000
initLimit=10
syncLimit=5
dataDir=/home/zookeeper/data
clientPort=2181
maxClientCnxns=60
autopurge.snapRetainCount=3
autopurge.purgeInterval=24
dataLogDir=/home/zookeeper/logs
server.1=172.16.218.201:2888:3888
server.2=172.16.218.202:2888:3888
server.3=172.16.218.203:2888:3888
7、创建zk的数据目录和日志目录
# mkdir -p /data/zookeeper/data/
# mkdir -p /data/zookeeper/logs
8、节点创建myid文件，节点对应id
在201机器上创建myid，并设置为1与配置文件zoo.cfg里面server.1对应。
# cd /data/zookeeper/data
# echo 1 > myid
在202机器上创建myid，并设置为2与配置文件zoo.cfg里面server.2对应。
echo "2" > /data/zookeeper/data/myid
在203机器上创建myid，并设置为3与配置文件zoo.cfg里面server.3对应。
echo "3" > /data/zookeeper/data/myid
9、服务启动
# cd /usr/local/zookeeper/bin/
# ./zkServer.sh start
# netstat -lutnp |grep java
tcp        0      0 0.0.0.0:2181    
10、设置开机自启动
vim /etc/rc.local 添加：
/usr/local/zookeeper-node1/bin/zkServer.sh start
11、检查状态
# ./zkServer.sh status
ZooKeeper JMX enabled by default
Using config: /usr/local/zookeeper-node2/bin/../conf/zoo.cfg
Mode: leader
二、部署kafka集群（201、202、203）
1、下载kafka
网址：https://kafka.apache.org/downloads
2、在/data下新建目录kafka,解压安装包在该目录
mkdir kafka
mkdir -p /data/kafka/kafkalogs
cd /data/kafka
tar -zxvf kafka_2.12-0.11.0.0.tgz
3、修改配置文件（只需修改config下server.properties）
cd /data/kafka/kafka_2.12-0.11.0.0/config
vim server.properties

#broker.id=0   每台服务器的broker.id都不能相同(1/2/3)
#hostname
host.name=172.16.218.201
#在log.retention.hours=168 下面新增下面三项
message.max.byte=5242880
default.replication.factor=2
replica.fetch.max.bytes=5242880
#设置zookeeper的连接端口
zookeeper.connect=172.16.218.201:2181,172.16.218.202:2181,172.16.218.203:2181
4、启动kafka（3台都需要启动）
cd /data/kafka/kafka_2.12-0.11.0.0/bin #进入到kafka的bin目录 
./kafka-server-start.sh -daemon ../config/server.properties &
5、检查是否启动成功
执行命令：
[root@mariadb-node1 config] # jps
1618 Jps
27987 QuorumPeerMain
1260 Kafka
6、创建topic验证是否成功
#创建Topic
./kafka-topics.sh --create --zookeeper 172.16.218.201:2181,172.16.218.202:2181,172.16.218.203:2181 --replication-factor 2 --partitions 1 --topic shequ
#解释
--replication-factor 2   #复制两份
--partitions 1 #创建1个分区
--topic #主题为shequ
#查看已创建的topic
./kafka-topics.sh --list --zookeeper 172.16.218.201:2181,172.16.218.202:2181,172.16.218.203:2181 
'''在一台服务器上创建一个发布者'''#创建一个broker，发布者
./kafka-console-producer.sh --broker-list 172.16.218.201:19092 --topic shequ
7、产生消息(202)
# ./kafka-console-producer.sh --broker-list 172.16.218.202:19092 --topic test 
> Hello world
> Hello kafka
8、消费消息(201/203)
./kafka-console-consumer.sh --zookeeper 172.16.218.201:2181,172.16.218.202:2181,172.16.218.203:2181  --topic test --from-beginning
Hello world
Hello kafka
9、使用 describe 命令来显示 topic 详情
./kafka-topics.sh --describe --zookeeper 172.16.218.201:2181,172.16.218.202:2181,172.16.218.203:2181 --topic test
Topic:test    PartitionCount:1    ReplicationFactor:2    Configs:
    Topic: test    Partition: 0    Leader: 3    Replicas: 3,2    Isr: 3,2
1） Leader 是给定分区的节点编号，每个分区的部分数据会随机指定不同的节点
2） Replicas 是该日志会保存的复制
3） Isr 表示正在同步的复制
10、删除topic
./kafka-topics.sh --delete --zookeeper 172.16.218.201:2181,172.16.218.202:2181,172.16.218.203:2181 --topic test
Topic test is marked for deletion.
Note: This will have no impact if delete.topic.enable is not set to true.
三、安装kafka-manager
功能：
为了简化开发者和服务工程师维护Kafka集群的工作，yahoo构建了一个叫做Kafka管理器的基于Web工具，叫做 Kafka Manager。这个管理工具可以很容易地发现分布在集群中的哪些topic分布不均匀，或者是分区在整个集群分布不均匀的的情况。它支持管理多个集群、选择副本、副本重新分配以及创建Topic。同时，这个管理工具也是一个非常好的可以快速浏览这个集群的工具，有如下功能：

1.管理多个kafka集群
2.便捷的检查kafka集群状态(topics,brokers,备份分布情况,分区分布情况)
3.选择你要运行的副本
4.基于当前分区状况进行
5.可以选择topic配置并创建topic(0.8.1.1和0.8.2的配置不同)
6.删除topic(只支持0.8.2以上的版本并且要在broker配置中设置delete.topic.enable=true)
7.Topic list会指明哪些topic被删除（在0.8.2以上版本适用）
8.为已存在的topic增加分区
9.为已存在的topic更新配置
10.在多个topic上批量重分区
11.在多个topic上批量重分区(可选partition broker位置)
安装步骤

1、获取kafka-manager源码，并编译打包
# cd /usr/local
# git clone https://github.com/yahoo/kafka-manager
# cd kafka-manager
# ./sbt clean dist
注: 执行sbt编译打包可能花费很长时间，如果你hang在如下情况
将project/plugins.sbt 中的logLevel参数修改为logLevel := Level.Debug(默认为Warn)

2、安装配置
编译成功后，会在target/universal下生成一个zip包

# cd /usr/local/kafka-manager/target/universal
# unzip kafka-manager-1.3.3.7.zip  
将application.conf中的kafka-manager.zkhosts的值设置为你的zk地址
如：kafka-manager.zkhosts="172.16.218.201:2181,172.16.218.202:2181,172.16.218.203:2181"
3、启动,指定配置文件位置和启动端口号，默认为9000
直接启动：

# cd kafka-manager-1.3.3.7/bin 
# ./kafka-manager -Dconfig.file=../conf/application.conf
后台运行：

# ./kafka-manager -h 
# nohup ./kafka-manager -Dconfig.file=../conf/application.conf &
指定端口，例如：

# nohup bin/kafka-manager -Dconfig.file=conf/application.conf -Dhttp.port=9001 &
第一次进入web UI要进行kafka cluster的相关配置，根据自己的信息进行配置。

4、进入web页面
网址：http://172.16.200.48:9000/



5、添加cluster


添加kafka集群成功后，点击进去，界面如下：



6、添加topic
